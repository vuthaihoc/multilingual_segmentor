# Text Segmentation API

API nÃ y cung cáº¥p cÃ¡c endpoint Ä‘á»ƒ tÃ¡ch cÃ¢u vÃ  tá»« (tokenization) cho nhiá»u ngÃ´n ngá»¯: tiáº¿ng Viá»‡t, tiáº¿ng Trung, tiáº¿ng Nháº­t, tiáº¿ng HÃ n vÃ  tiáº¿ng Anh.  

---

## ğŸ“¦ YÃªu cáº§u

- Python 3.9+
- ThÆ° viá»‡n:

```text
fastapi>=0.95.0
uvicorn>=0.22.0
langid>=1.1.6
jieba>=0.42.1
fugashi>=1.2.1
unidic-lite>=1.0.8
konlpy>=0.6.0
nltk>=3.8.1
pycountry>=22.3.5
underthesea>=1.3.4
````

CÃ i Ä‘áº·t táº¥t cáº£ thÆ° viá»‡n:

```bash
pip install -r requirements.txt
```

---

## ğŸš€ Khá»Ÿi cháº¡y server

```bash
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

Server sáº½ cháº¡y trÃªn: `http://localhost:8000`

---

## ğŸ“ Input Model

Cáº£ 2 API Ä‘á»u sá»­ dá»¥ng cÃ¹ng Ä‘á»‹nh dáº¡ng input JSON:

```json
{
  "text": "Äoáº¡n vÄƒn hoáº·c cÃ¢u cáº§n tÃ¡ch tá»«.",
  "language_code": "vi",    // tÃ¹y chá»n, override detect
  "force_nltk": false        // tÃ¹y chá»n, náº¿u true luÃ´n dÃ¹ng NLTK tokenizer
}
```

* `text`: Ä‘oáº¡n vÄƒn hoáº·c cÃ¢u muá»‘n segment.
* `language_code`: mÃ£ ngÃ´n ngá»¯ 2 kÃ½ tá»± ISO-639-1 (náº¿u khÃ´ng truyá»n, há»‡ thá»‘ng sáº½ detect tá»± Ä‘á»™ng).
* `force_nltk`: náº¿u `true`, sáº½ dÃ¹ng NLTK tokenizer cho táº¥t cáº£ ngÃ´n ngá»¯.

---

## ğŸ“Œ API Endpoints

### 1. `/segment`

TÃ¡ch **má»™t cÃ¢u hoáº·c má»™t Ä‘oáº¡n ngáº¯n** thÃ nh tokens (tá»«).

* **Method:** POST
* **URL:** `/segment`
* **Request Example:**

```json
{
  "text": "Xin chÃ o tháº¿ giá»›i!",
  "language_code": "vi",
  "force_nltk": false
}
```

* **Response Example:**

```json
{
  "language_code": "vi",
  "force_nltk": false,
  "tokens": ["Xin", "chÃ o", "tháº¿", "giá»›i", "!"]
}
```

---

### 2. `/paragraph/segment`

TÃ¡ch **má»™t Ä‘oáº¡n vÄƒn dÃ i** thÃ nh cÃ¢u, sau Ä‘Ã³ tÃ¡ch tá»« tá»«ng cÃ¢u.

* **Method:** POST
* **URL:** `/paragraph/segment`
* **Request Example:**

```json
{
  "text": "Xin chÃ o! TÃ´i tÃªn lÃ  ChatGPT. Ráº¥t vui Ä‘Æ°á»£c gáº·p báº¡n.",
  "language_code": "vi",
  "force_nltk": false
}
```

* **Response Example:**

```json
{
  "language_code": "vi",
  "force_nltk": false,
  "sentences": [
    {
      "sentence": "Xin chÃ o!",
      "tokens": ["Xin", "chÃ o", "!"]
    },
    {
      "sentence": "TÃ´i tÃªn lÃ  ChatGPT.",
      "tokens": ["TÃ´i", "tÃªn", "lÃ ", "ChatGPT", "."]
    },
    {
      "sentence": "Ráº¥t vui Ä‘Æ°á»£c gáº·p báº¡n.",
      "tokens": ["Ráº¥t", "vui", "Ä‘Æ°á»£c", "gáº·p", "báº¡n", "."]
    }
  ]
}
```

---

## ğŸ”§ LÆ°u Ã½

* Há»— trá»£ cÃ¡c ngÃ´n ngá»¯:

  * Tiáº¿ng Viá»‡t (`vi`) â†’ `underthesea`
  * Tiáº¿ng Trung (`zh`) â†’ `jieba`
  * Tiáº¿ng Nháº­t (`ja`) â†’ `fugashi`
  * Tiáº¿ng HÃ n (`ko`) â†’ `konlpy.Okt`
  * Tiáº¿ng Anh vÃ  cÃ¡c ngÃ´n ngá»¯ khÃ¡c â†’ `nltk`

* `language_code` máº·c Ä‘á»‹nh Ä‘Æ°á»£c detect báº±ng `langid.py`.

* `force_nltk=True` sáº½ bá» qua detect vÃ  tokenizers riÃªng theo ngÃ´n ngá»¯, luÃ´n dÃ¹ng NLTK.

---

## âš¡ Test nhanh vá»›i `curl`

```bash
curl -X POST "http://localhost:8000/segment" \
-H "Content-Type: application/json" \
-d '{"text":"Xin chÃ o tháº¿ giá»›i!","language_code":"vi"}'

curl -X POST "http://localhost:8000/paragraph/segment" \
-H "Content-Type: application/json" \
-d '{"text":"Xin chÃ o! TÃ´i tÃªn lÃ  ChatGPT.","language_code":"vi"}'
```

---

## ğŸ“š TÃ i liá»‡u

* [FastAPI](https://fastapi.tiangolo.com/)
* [NLTK](https://www.nltk.org/)
* [Underthesea](https://github.com/underthesea/underthesea)
* [jieba](https://github.com/fxsjy/jieba)
* [Fugashi](https://pypi.org/project/fugashi/)
* [Konlpy](https://konlpy.org/en/latest/)
* [langid.py](https://github.com/saffsd/langid.py)

```

---