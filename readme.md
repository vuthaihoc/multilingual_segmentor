# FastAPI Text Segmentation & Transliteration API

API nÃ y cung cáº¥p cÃ¡c endpoint Ä‘á»ƒ:

- TÃ¡ch tá»« (tokenize) cho nhiá»u ngÃ´n ngá»¯: **Tiáº¿ng Trung, Nháº­t, HÃ n, Viá»‡t, vÃ  cÃ¡c ngÃ´n ngá»¯ khÃ¡c**
- TÃ¡ch cÃ¢u vÃ  tokenize tá»«ng cÃ¢u
- **Transliteration** cho CJK (Chinese / Japanese / Korean) tÆ°Æ¡ng á»©ng vá»›i má»—i token
- Há»— trá»£ **bulk processing** cho nhiá»u Ä‘oáº¡n text cÃ¹ng lÃºc

---

## ğŸ“¦ YÃªu cáº§u

- Python â‰¥ 3.10
- FastAPI
- langid
- nltk
- jieba
- fugashi
- konlpy
- underthesea
- pypinyin
- pykakasi
- hgtk

---

### `requirements.txt` vÃ­ dá»¥

```
fastapi
uvicorn
langid
nltk
jieba
fugashi
konlpy
underthesea
pypinyin==0.55.0
pykakasi==2.3.0
hgtk==0.2.1
```

---

## ğŸš€ CÃ i Ä‘áº·t & cháº¡y server

```bash
pip install -r requirements.txt

# cháº¡y server
uvicorn main:app --reload
```

Máº·c Ä‘á»‹nh API sáº½ cháº¡y táº¡i `http://127.0.0.1:8000`.

---

## ğŸ“Œ Endpoints

### 1. `/segment` â€” tokenize 1 Ä‘oáº¡n text

**Request JSON:**

```json
{
  "text": "çªç„¶é—´ï¼Œä¸€åˆ‡éƒ½å´©å¡Œäº†",
  "language_code": "zh",
  "force_nltk": false
}
```

**Response JSON:**

```json
{
  "language_code": "zh",
  "force_nltk": false,
  "tokens": [
    { "token": "çªç„¶é—´", "transliteration": "turanjian" },
    { "token": "ï¼Œ", "transliteration": "ï¼Œ" },
    { "token": "ä¸€åˆ‡", "transliteration": "yiqie" },
    { "token": "éƒ½", "transliteration": "dou" },
    { "token": "å´©å¡Œ", "transliteration": "bengta" },
    { "token": "äº†", "transliteration": "le" }
  ]
}
```

---

### 2. `/paragraph/segment` â€” tÃ¡ch cÃ¢u + tokenize tá»«ng cÃ¢u

**Request JSON:**

```json
{
  "text": "Xin chÃ o. TÃ´i lÃ  ChatGPT.",
  "language_code": "vi"
}
```

**Response JSON:**

```json
{
  "language_code": "vi",
  "force_nltk": false,
  "sentences": [
    {
      "sentence": "Xin chÃ o.",
      "tokens": [
        { "token": "Xin", "transliteration": "Xin" },
        { "token": "chÃ o", "transliteration": "chÃ o" },
        { "token": ".", "transliteration": "." }
      ]
    },
    {
      "sentence": "TÃ´i lÃ  ChatGPT.",
      "tokens": [
        { "token": "TÃ´i", "transliteration": "TÃ´i" },
        { "token": "lÃ ", "transliteration": "lÃ " },
        { "token": "ChatGPT", "transliteration": "ChatGPT" },
        { "token": ".", "transliteration": "." }
      ]
    }
  ]
}
```

---

### 3. `/bulk/segment` â€” tokenize nhiá»u Ä‘oáº¡n text cÃ¹ng lÃºc

**Request JSON:**

```json
{
  "items": [
    { "text": "çªç„¶é—´ï¼Œä¸€åˆ‡éƒ½å´©å¡Œäº†" },
    { "text": "ã“ã‚“ã«ã¡ã¯ã€å…ƒæ°—ã§ã™ã‹ï¼Ÿ" },
    { "text": "ì•ˆë…•í•˜ì„¸ìš”" }
  ]
}
```

**Response JSON:**

```json
{
  "results": [
    {
      "language_code": "zh",
      "force_nltk": false,
      "tokens": [
        { "token": "çªç„¶é—´", "transliteration": "turanjian" },
        { "token": "ï¼Œ", "transliteration": "ï¼Œ" },
        { "token": "ä¸€åˆ‡", "transliteration": "yiqie" },
        { "token": "éƒ½", "transliteration": "dou" },
        { "token": "å´©å¡Œ", "transliteration": "bengta" },
        { "token": "äº†", "transliteration": "le" }
      ]
    },
    {
      "language_code": "ja",
      "force_nltk": false,
      "tokens": [
        { "token": "ã“ã‚“ã«ã¡ã¯", "transliteration": "konnichiwa" },
        { "token": "ã€", "transliteration": "ã€" },
        { "token": "å…ƒæ°—", "transliteration": "genki" },
        { "token": "ã§ã™", "transliteration": "desu" },
        { "token": "ã‹", "transliteration": "ka" },
        { "token": "ï¼Ÿ", "transliteration": "ï¼Ÿ" }
      ]
    },
    {
      "language_code": "ko",
      "force_nltk": false,
      "tokens": [{ "token": "ì•ˆë…•í•˜ì„¸ìš”", "transliteration": "annyeonghaseyo" }]
    }
  ]
}
```

---

### 4. VÃ­ dá»¥ `curl` sá»­ dá»¥ng inline JSON

```bash
curl -X POST "http://127.0.0.1:8000/bulk/segment" \
     -H "Content-Type: application/json" \
     -d '{
           "items": [
             {"text": "çªç„¶é—´ï¼Œä¸€åˆ‡éƒ½å´©å¡Œäº†"},
             {"text": "ã“ã‚“ã«ã¡ã¯ã€å…ƒæ°—ã§ã™ã‹ï¼Ÿ"},
             {"text": "ì•ˆë…•í•˜ì„¸ìš”"}
           ]
         }'
```
